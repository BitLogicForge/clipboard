{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Height vs Weight Dataset with Polynomial Regression\n",
    "\n",
    "This notebook demonstrates a non-linear relationship between height and weight using a synthetic dataset where linear regression is insufficient and polynomial regression is required.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration Parameters\n",
    "\n",
    "This section contains adjustable parameters for the dataset generation and visualization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration parameters\n",
    "config = {\n",
    "    # Dataset parameters\n",
    "    \"n_samples\": 200,  # Number of samples to generate\n",
    "    \"random_seed\": 42,  # Random seed for reproducibility\n",
    "    # Height distribution parameters\n",
    "    \"height_mean\": 170,  # Mean height in cm\n",
    "    \"height_std\": 15,  # Standard deviation for height\n",
    "    # Weight parameters - non-linear relationship\n",
    "    \"base_weight\": -210,  # Base weight component\n",
    "    \"height_factor\": 0.11,  # Weight factor for quadratic term\n",
    "    \"linear_factor\": 0.21,  # Weight factor for linear term\n",
    "    \"weight_noise_std\": 15,  # Standard deviation of noise in weight\n",
    "    # Polynomial regression parameters\n",
    "    \"poly_degree\": 2,  # Degree of the polynomial\n",
    "    # Plot parameters\n",
    "    \"plot_figsize\": (14, 8),  # Figure size\n",
    "    \"scatter_alpha\": 0.6,  # Transparency of scatter points\n",
    "    \"scatter_color\": \"blue\",  # Color of scatter points\n",
    "    \"line_color_linear\": \"red\",  # Color of linear regression line\n",
    "    \"line_color_poly\": \"green\",  # Color of polynomial regression line\n",
    "    \"line_width\": 2,  # Width of regression line\n",
    "    \"grid_alpha\": 0.3,  # Transparency of grid lines\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(config[\"random_seed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate heights in cm (normally distributed)\n",
    "heights = np.random.normal(config[\"height_mean\"], config[\"height_std\"], config[\"n_samples\"])\n",
    "\n",
    "# Create weights with a non-linear relationship to height plus some noise\n",
    "# Weight = base_weight + (height_factor * height^2) + (linear_factor * height) + noise\n",
    "noise = np.random.normal(0, config[\"weight_noise_std\"], config[\"n_samples\"])\n",
    "weights = (\n",
    "    config[\"base_weight\"]\n",
    "    + (config[\"height_factor\"] * heights**2)\n",
    "    + (config[\"linear_factor\"] * heights)\n",
    "    + noise\n",
    ")\n",
    "\n",
    "# Create a DataFrame\n",
    "data = pd.DataFrame({\"Height (cm)\": heights, \"Weight (kg)\": weights})\n",
    "\n",
    "# Display the first few rows\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "Let's analyze the dataset from a data scientist's perspective.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display descriptive statistics\n",
    "print(\"Descriptive Statistics:\")\n",
    "display(data.describe())\n",
    "\n",
    "# Calculate correlation\n",
    "correlation = data[\"Height (cm)\"].corr(data[\"Weight (kg)\"])\n",
    "print(f\"\\nCorrelation between Height and Weight: {correlation:.4f}\")\n",
    "\n",
    "# Scatter plot to visualize the relationship\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(data[\"Height (cm)\"], data[\"Weight (kg)\"], alpha=0.6)\n",
    "plt.title(\"Height vs Weight - Non-linear Relationship\")\n",
    "plt.xlabel(\"Height (cm)\")\n",
    "plt.ylabel(\"Weight (kg)\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression (Insufficient Model)\n",
    "\n",
    "First, let's try fitting a simple linear regression model to see why it's insufficient.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for linear regression\n",
    "X = data[\"Height (cm)\"].to_numpy().reshape(-1, 1)  # Independent variable\n",
    "y = data[\"Weight (kg)\"].to_numpy()  # Dependent variable\n",
    "\n",
    "# Create and fit the linear regression model\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X, y)\n",
    "\n",
    "# Get the coefficient (slope) and intercept\n",
    "slope = linear_model.coef_[0]\n",
    "intercept = linear_model.intercept_\n",
    "\n",
    "# Make predictions\n",
    "y_pred_linear = linear_model.predict(X)\n",
    "\n",
    "# Calculate metrics for linear model\n",
    "mse_linear = mean_squared_error(y, y_pred_linear)\n",
    "r2_linear = r2_score(y, y_pred_linear)\n",
    "\n",
    "print(f\"Linear Regression Model: Weight = {slope:.4f} × Height + {intercept:.4f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse_linear:.4f}\")\n",
    "print(f\"R-squared (R²): {r2_linear:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Regression (Better Model)\n",
    "\n",
    "Now let's implement polynomial regression to better fit the non-linear relationship.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and fit a polynomial regression model\n",
    "poly_model = make_pipeline(PolynomialFeatures(degree=config[\"poly_degree\"]), LinearRegression())\n",
    "poly_model.fit(X, y)\n",
    "\n",
    "# Make predictions with the polynomial model\n",
    "y_pred_poly = poly_model.predict(X)\n",
    "\n",
    "# Calculate metrics for polynomial model\n",
    "mse_poly = mean_squared_error(y, y_pred_poly)\n",
    "r2_poly = r2_score(y, y_pred_poly)\n",
    "\n",
    "# Extract polynomial coefficients\n",
    "coefficients = poly_model.named_steps[\"linearregression\"].coef_\n",
    "intercept_poly = poly_model.named_steps[\"linearregression\"].intercept_\n",
    "\n",
    "print(\"Polynomial Regression Model:\")\n",
    "print(f\"Intercept: {intercept_poly:.4f}\")\n",
    "for i, coef in enumerate(coefficients):\n",
    "    if i > 0:  # Skip the first coefficient which is always 0\n",
    "        print(f\"Coefficient for degree {i}: {coef:.6f}\")\n",
    "print(f\"\\nMean Squared Error (MSE): {mse_poly:.4f}\")\n",
    "print(f\"R-squared (R²): {r2_poly:.4f}\")\n",
    "print(f\"\\nImprovement in MSE: {mse_linear - mse_poly:.4f} ({(1 - mse_poly/mse_linear) * 100:.2f}%)\")\n",
    "print(f\"Improvement in R²: {r2_poly - r2_linear:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization to compare linear and polynomial models\n",
    "plt.figure(figsize=config[\"plot_figsize\"])\n",
    "\n",
    "# Original data points\n",
    "plt.scatter(\n",
    "    data[\"Height (cm)\"],\n",
    "    data[\"Weight (kg)\"],\n",
    "    alpha=config[\"scatter_alpha\"],\n",
    "    color=config[\"scatter_color\"],\n",
    "    label=\"Data points\",\n",
    ")\n",
    "\n",
    "# Sort X for smoother lines\n",
    "X_sorted = np.sort(X, axis=0)\n",
    "y_linear_sorted = linear_model.predict(X_sorted)\n",
    "y_poly_sorted = poly_model.predict(X_sorted)\n",
    "\n",
    "# Linear regression line\n",
    "plt.plot(\n",
    "    X_sorted,\n",
    "    y_linear_sorted,\n",
    "    color=config[\"line_color_linear\"],\n",
    "    linewidth=config[\"line_width\"],\n",
    "    label=f\"Linear model (R² = {r2_linear:.4f})\",\n",
    ")\n",
    "\n",
    "# Polynomial regression line\n",
    "plt.plot(\n",
    "    X_sorted,\n",
    "    y_poly_sorted,\n",
    "    color=config[\"line_color_poly\"],\n",
    "    linewidth=config[\"line_width\"],\n",
    "    label=f\"Polynomial model (R² = {r2_poly:.4f})\",\n",
    ")\n",
    "\n",
    "plt.title(\"Comparison of Linear vs Polynomial Regression\", fontsize=14)\n",
    "plt.xlabel(\"Height (cm)\", fontsize=12)\n",
    "plt.ylabel(\"Weight (kg)\", fontsize=12)\n",
    "plt.grid(True, alpha=config[\"grid_alpha\"])\n",
    "plt.legend(fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual Analysis\n",
    "\n",
    "Let's compare the residuals from both models to visualize the improvement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate residuals for both models\n",
    "residuals_linear = y - y_pred_linear\n",
    "residuals_poly = y - y_pred_poly\n",
    "\n",
    "# Create a figure with 2 rows and 2 columns\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Residuals vs. Fitted values plot for linear model\n",
    "axes[0, 0].scatter(y_pred_linear, residuals_linear, alpha=0.6)\n",
    "axes[0, 0].axhline(y=0, color=\"r\", linestyle=\"-\")\n",
    "axes[0, 0].set_xlabel(\"Predicted Weight (kg)\")\n",
    "axes[0, 0].set_ylabel(\"Residuals\")\n",
    "axes[0, 0].set_title(\"Linear Model: Residuals vs Fitted Values\")\n",
    "axes[0, 0].grid(alpha=0.3)\n",
    "\n",
    "# Histogram of residuals for linear model\n",
    "sns.histplot(residuals_linear, kde=True, ax=axes[0, 1], color=\"red\", alpha=0.6)\n",
    "axes[0, 1].axvline(x=0, color=\"k\", linestyle=\"-\")\n",
    "axes[0, 1].set_xlabel(\"Residual Value\")\n",
    "axes[0, 1].set_title(\n",
    "    f\"Linear Model: Distribution of Residuals (std={np.std(residuals_linear):.2f})\"\n",
    ")\n",
    "axes[0, 1].grid(alpha=0.3)\n",
    "\n",
    "# Residuals vs. Fitted values plot for polynomial model\n",
    "axes[1, 0].scatter(y_pred_poly, residuals_poly, alpha=0.6, color=\"green\")\n",
    "axes[1, 0].axhline(y=0, color=\"r\", linestyle=\"-\")\n",
    "axes[1, 0].set_xlabel(\"Predicted Weight (kg)\")\n",
    "axes[1, 0].set_ylabel(\"Residuals\")\n",
    "axes[1, 0].set_title(\"Polynomial Model: Residuals vs Fitted Values\")\n",
    "axes[1, 0].grid(alpha=0.3)\n",
    "\n",
    "# Histogram of residuals for polynomial model\n",
    "sns.histplot(residuals_poly, kde=True, ax=axes[1, 1], color=\"green\", alpha=0.6)\n",
    "axes[1, 1].axvline(x=0, color=\"k\", linestyle=\"-\")\n",
    "axes[1, 1].set_xlabel(\"Residual Value\")\n",
    "axes[1, 1].set_title(\n",
    "    f\"Polynomial Model: Distribution of Residuals (std={np.std(residuals_poly):.2f})\"\n",
    ")\n",
    "axes[1, 1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Example\n",
    "\n",
    "Using both models to predict weights for new height values and comparing the predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example predictions for different heights\n",
    "example_heights = np.array([150, 160, 170, 180, 190, 200])\n",
    "example_heights_reshaped = example_heights.reshape(-1, 1)\n",
    "\n",
    "# Make predictions with both models\n",
    "linear_predictions = linear_model.predict(example_heights_reshaped)\n",
    "poly_predictions = poly_model.predict(example_heights_reshaped)\n",
    "\n",
    "# Create a DataFrame for the comparison\n",
    "comparison_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Height (cm)\": example_heights,\n",
    "        \"Linear Model Prediction (kg)\": linear_predictions,\n",
    "        \"Polynomial Model Prediction (kg)\": poly_predictions,\n",
    "        \"Difference (kg)\": poly_predictions - linear_predictions,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Display the comparison\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrates how polynomial regression can significantly improve model fit when the relationship between variables is non-linear. The key observations are:\n",
    "\n",
    "1. The simple linear regression model failed to capture the curvature in the data\n",
    "2. The polynomial regression model provided a much better fit as shown by the improved R² and MSE values\n",
    "3. The residual analysis shows that the polynomial model's residuals are more randomly distributed around zero\n",
    "4. The predictions from the polynomial model better reflect the true non-linear relationship in the data\n",
    "\n",
    "This illustrates why it's important to explore different model types beyond simple linear regression when working with real-world data that may contain non-linear relationships.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyt12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
