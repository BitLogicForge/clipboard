{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "639a94cd",
   "metadata": {},
   "source": [
    "# Analyzing Word Similarity with Pre-trained GloVe Embeddings\n",
    "\n",
    "This notebook demonstrates how to use pre-trained GloVe embeddings to analyze word similarity and visualize word relationships.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a9ec14",
   "metadata": {},
   "source": [
    "## 1. Introduction to GloVe\n",
    "\n",
    "GloVe (Global Vectors for Word Representation) is a pre-trained word embedding model that captures semantic relationships between words.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3fc49dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1706c07d",
   "metadata": {},
   "source": [
    "## 2. Load Pre-trained GloVe Embeddings\n",
    "\n",
    "We will load the GloVe embeddings from a file. Ensure you have downloaded the GloVe file (e.g., `glove.6B.50d.txt`).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acf154d",
   "metadata": {},
   "source": [
    "## Downloading GloVe Embeddings\n",
    "\n",
    "To use GloVe embeddings, you need to download the pre-trained embeddings from the official website:\n",
    "\n",
    "1. Visit [GloVe Website](https://nlp.stanford.edu/projects/glove/).\n",
    "2. Download the desired embedding file, such as `glove.6B.zip`.\n",
    "3. Extract the contents of the zip file to a directory on your system.\n",
    "4. Note the path to the extracted file, e.g., `glove.6B.50d.txt`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbeced2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GloVe file not found at glove.6B.50d.txt. Please download it from https://nlp.stanford.edu/projects/glove/\n"
     ]
    }
   ],
   "source": [
    "# Load GloVe embeddings with error handling\n",
    "import os\n",
    "\n",
    "\n",
    "def load_glove_embeddings(file_path):\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(\n",
    "            f\"GloVe file not found at {file_path}. Please download it from https://nlp.stanford.edu/projects/glove/\"\n",
    "        )\n",
    "    embeddings = {}\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.array(values[1:], dtype=\"float32\")\n",
    "            embeddings[word] = vector\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "# Specify the path to the GloVe file\n",
    "glove_file = \"glove.6B.50d.txt\"\n",
    "try:\n",
    "    embeddings = load_glove_embeddings(glove_file)\n",
    "    print(f\"Loaded {len(embeddings)} word vectors.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fd5e21",
   "metadata": {},
   "source": [
    "## 3. Find Similar Words\n",
    "\n",
    "We will use cosine similarity to find words similar to a given word.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cae8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find similar words\n",
    "def find_similar_words(word, embeddings, top_n=5):\n",
    "    if word not in embeddings:\n",
    "        return f\"{word} not found in embeddings.\"\n",
    "    word_vector = embeddings[word].reshape(1, -1)\n",
    "    similarities = {}\n",
    "    for other_word, other_vector in embeddings.items():\n",
    "        if other_word != word:\n",
    "            similarity = cosine_similarity(word_vector, other_vector.reshape(1, -1))[0, 0]\n",
    "            similarities[other_word] = similarity\n",
    "    sorted_words = sorted(similarities.items(), key=lambda x: x[1], reverse=True)[:top_n]\n",
    "    return sorted_words\n",
    "\n",
    "\n",
    "# Example: Find words similar to 'king'\n",
    "similar_words = find_similar_words(\"king\", embeddings)\n",
    "print(similar_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad67ba85",
   "metadata": {},
   "source": [
    "## 4. Visualize Word Relationships\n",
    "\n",
    "We will use t-SNE to reduce the dimensionality of word vectors and visualize their relationships.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23597c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize word relationships\n",
    "def visualize_words(words, embeddings):\n",
    "    vectors = np.array([embeddings[word] for word in words if word in embeddings])\n",
    "    tsne = TSNE(n_components=2, random_state=42)\n",
    "    reduced_vectors = tsne.fit_transform(vectors)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for i, word in enumerate(words):\n",
    "        if word in embeddings:\n",
    "            plt.scatter(reduced_vectors[i, 0], reduced_vectors[i, 1], label=word)\n",
    "            plt.text(reduced_vectors[i, 0] + 0.1, reduced_vectors[i, 1] + 0.1, word, fontsize=12)\n",
    "    plt.title(\"Word Relationships\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Example: Visualize relationships among selected words\n",
    "words_to_visualize = [\"king\", \"queen\", \"man\", \"woman\", \"prince\", \"princess\"]\n",
    "visualize_words(words_to_visualize, embeddings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyt12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
