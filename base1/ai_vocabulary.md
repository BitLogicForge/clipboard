# AI Vocabulary Reference Guide

This guide provides definitions for key AI terminology organized by difficulty level to help learners build their understanding progressively.

## Table of Contents
1. [Basic Terminology](#basic-terminology)
2. [Intermediate Terminology](#intermediate-terminology)
3. [Advanced Terminology](#advanced-terminology)

## Basic Terminology

### Algorithm
A step-by-step procedure or set of rules designed to perform a specific task or solve a particular problem.

### Artificial Intelligence (AI)
Systems that can perform tasks that typically require human intelligence, such as visual perception, speech recognition, decision-making, and language translation.

### Data
Information used by AI systems to learn patterns, make predictions, or generate content.

### Dataset
A collection of data samples used for training, testing, and evaluating AI models.

### Feature
An individual measurable property or characteristic of the data being observed. Features are the inputs to machine learning models.

### Label
The output or target variable that a machine learning model is trying to predict based on input features.

### Machine Learning (ML)
A subset of AI that enables systems to learn and improve from experience without being explicitly programmed.

### Model
A mathematical representation trained on data to make predictions or decisions without being explicitly programmed for the task.

### Prediction
The output of a machine learning model when given input data.

### Training
The process of teaching a machine learning model to make predictions by showing it examples.

### Testing
The process of evaluating a trained model's performance on data it hasn't seen during training.

### Validation
The process of fine-tuning model parameters using a separate dataset to prevent overfitting.

## Intermediate Terminology

### Accuracy
The proportion of correct predictions made by a model out of all predictions.

### Batch
A group of samples processed together by a model during training.

### Bias
1. Statistical bias in models that causes systematic errors
2. Prejudice in data or algorithms that leads to unfair outcomes

### Classification
A type of supervised learning task where the model predicts discrete categories or classes.

### Clustering
An unsupervised learning technique that groups similar data points together.

### Deep Learning
A subset of machine learning that uses neural networks with multiple layers to progressively extract higher-level features from raw input.

### Epoch
One complete pass through the entire training dataset during model training.

### Generative AI
AI systems that can create new content, such as text, images, or music, that resembles human-created content.

### Gradient Descent
An optimization algorithm that iteratively adjusts model parameters to minimize error.

### Hyperparameter
A parameter whose value is set before the learning process begins, as opposed to parameters which are learned during training.

### Neural Network
A computing system inspired by biological neural networks, consisting of interconnected nodes (neurons) that process and transmit information.

### Overfitting
When a model learns the training data too well, including its noise and outliers, resulting in poor performance on new, unseen data.

### Regression
A supervised learning task where the model predicts continuous numerical values.

### Supervised Learning
A type of machine learning where the model is trained on labeled data.

### Tokens
Units into which text is broken down for processing by language models. Tokens can be words, parts of words, or characters.

### Transfer Learning
A technique where a model developed for one task is reused as the starting point for a model on a second task.

### Underfitting
When a model is too simple to capture the underlying pattern in the data, resulting in poor performance on both training and new data.

### Unsupervised Learning
A type of machine learning where the model learns patterns from unlabeled data.

## Advanced Terminology

### Activation Function
A mathematical function that determines the output of a neural network node, introducing non-linearity to the model.

### Attention Mechanism
A technique that allows neural networks to focus on specific parts of the input when producing an output, mimicking human attention.

### Autoencoder
A type of neural network that learns efficient representations (encodings) of input data by trying to reconstruct the input from a compressed representation.

### Backpropagation
An algorithm for training neural networks by calculating gradients and updating weights to minimize error.

### Convolutional Neural Network (CNN)
A class of deep neural networks most commonly used for analyzing visual imagery and processing data with grid-like topology.

### Embeddings
Vector representations of discrete variables (like words or categories) that capture semantic relationships.

### Fine-tuning
The process of taking a pre-trained model and adapting it to a specific task or domain by continuing training on task-specific data.

### Generative Adversarial Network (GAN)
A machine learning framework where two neural networks (generator and discriminator) compete against each other, resulting in the generation of new, synthetic data.

### Hallucination
In AI systems, particularly language models, the generation of content that is factually incorrect or entirely fabricated but presented as true.

### Latent Space
A compressed representation of data points in a lower-dimensional space, where similar items are positioned closely together.

### Large Language Model (LLM)
A type of AI model trained on vast amounts of text data to understand and generate human-like text based on input prompts.

### Multimodal Learning
An approach that integrates multiple types of data (text, images, audio, etc.) for more comprehensive understanding.

### Prompt Engineering
The practice of designing and refining input prompts to elicit desired responses from language models.

### Reinforcement Learning
A type of machine learning where an agent learns to make decisions by performing actions and receiving rewards or penalties.

### Retrieval-Augmented Generation (RAG)
A technique that combines information retrieval with text generation to produce outputs that are more factually accurate by supplementing model knowledge with retrieved information.

### Recurrent Neural Network (RNN)
A class of neural networks designed to recognize patterns in sequences of data by maintaining a memory of previous inputs.

### Regularization
Techniques used to prevent overfitting by adding a penalty to the loss function during training.

### Transformer
A deep learning architecture that relies on self-attention mechanisms to process sequential data, forming the basis for models like GPT and BERT.

### Variational Autoencoder (VAE)
A type of autoencoder that adds constraints to the encoded representations, making the model generative and enabling it to create new data samples.

### Zero-shot Learning
The ability of a model to perform tasks it wasn't explicitly trained on, by leveraging knowledge gained during training on related tasks.
